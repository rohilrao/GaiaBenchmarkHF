{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892a5761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example from 2023_level1 ---\n",
      "task_id: e1fc63a2-da7a-432f-be78-7c4a95598703\n",
      "Question: If Eliud Kipchoge could maintain his record-making marathon pace indefinitely, how many thousand hours would it take him to run the distance between the Earth and the Moon its closest approach? Please use the minimum perigee value on the Wikipedia page for the Moon when carrying out your calculation. Round your result to the nearest 1000 hours and do not use any comma separators if necessary.\n",
      "Level: 1\n",
      "Final answer: 17\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Googled Eliud Kipchoge marathon pace to find 4min 37sec/mile\\n2. Converted into fractions of hours.\\n3. Found moon periapsis in miles (225,623 miles).\\n4. Multiplied the two to find the number of hours and rounded to the nearest 100 hours.', 'Number of steps': '4', 'How long did this take?': '20 Minutes', 'Tools': '1. A web browser.\\n2. A search engine.\\n3. A calculator.', 'Number of tools': '3'}\n",
      "\n",
      "--- Example from 2023_level2 ---\n",
      "task_id: c61d22de-5f6c-4958-a7f6-5e9707bd3466\n",
      "Question: A paper about AI regulation that was originally submitted to arXiv.org in June 2022 shows a figure with three axes, where each axis has a label word at both ends. Which of these words is used to describe a type of society in a Physics and Society article submitted to arXiv.org on August 11, 2016?\n",
      "Level: 2\n",
      "Final answer: egalitarian\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Go to arxiv.org and navigate to the Advanced Search page.\\n2. Enter \"AI regulation\" in the search box and select \"All fields\" from the dropdown.\\n3. Enter 2022-06-01 and 2022-07-01 into the date inputs, select \"Submission date (original)\", and submit the search.\\n4. Go through the search results to find the article that has a figure with three axes and labels on each end of the axes, titled \"Fairness in Agreement With European Values: An Interdisciplinary Perspective on AI Regulation\".\\n5. Note the six words used as labels: deontological, egalitarian, localized, standardized, utilitarian, and consequential.\\n6. Go back to arxiv.org\\n7. Find \"Physics and Society\" and go to the page for the \"Physics and Society\" category.\\n8. Note that the tag for this category is \"physics.soc-ph\".\\n9. Go to the Advanced Search page.\\n10. Enter \"physics.soc-ph\" in the search box and select \"All fields\" from the dropdown.\\n11. Enter 2016-08-11 and 2016-08-12 into the date inputs, select \"Submission date (original)\", and submit the search.\\n12. Search for instances of the six words in the results to find the paper titled \"Phase transition from egalitarian to hierarchical societies driven by competition between cognitive and social constraints\", indicating that \"egalitarian\" is the correct answer.', 'Number of steps': '12', 'How long did this take?': '8 minutes', 'Tools': '1. Web browser\\n2. Image recognition tools (to identify and parse a figure with three axes)', 'Number of tools': '2'}\n",
      "\n",
      "--- Example from 2023_level3 ---\n",
      "task_id: 676e5e31-a554-4acc-9286-b60d90a92d26\n",
      "Question: In July 2, 1959 United States standards for grades of processed fruits, vegetables, and certain other products listed as dehydrated, consider the items in the \"dried and dehydrated section\" specifically marked as dehydrated along with any items in the Frozen/Chilled section that contain the whole name of the item, but not if they're marked Chilled. As of August 2023, what is the percentage (to the nearest percent) of those standards that have been superseded by a new version since the date given in the 1959 standards?\n",
      "Level: 3\n",
      "Final answer: 86\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Searched \"July 2, 1959 United States standards for grades of processed fruits, vegetables, and certain other products\" on Google.\\n2. Opened https://upload.wikimedia.org/wikipedia/commons/0/06/United_States_standards_for_grades_of_processed_fruits%2C_vegetables%2C_and_certain_other_products_%28as_of_July_2%2C_1959%29_%28IA_unitedstatesstan14unit_4%29.pdf.\\n3. Scrolled to the \"DRIED or DEHYDRATED\" section.\\n4. Opened a new tab and searched \"united states standards for grades of dehydrated apples\".\\n5. Opened https://www.ams.usda.gov/grades-standards/dehydrated-apples-grades-and-standards.\\n6. Opened the \"U.S. Grade Standards for Dehydrated Apples (pdf)\" PDF.\\n7. Checked the date against the 1959 standards.\\n8. Repeated steps 4-7 for all dehydrated items in the \"DRIED or DEHYDRATED\" section:\\n9. Grapefruit Juice, updated (running tally: 2/2)\\n10. Orange Juice, updated (running tally: 3/3)\\n11. Found all versions of the dehydrated items in Frozen or Chilled, except those marked Chilled: Apples; Grapefruit Juice, Concentrated; Grapefruit Juice and Orange Juice, Concentrated, Blended; Orange Juice, Concentrated\\n12. Repeated steps 4-7 all those versions:\\n13. Apples, not updated (running tally: 3/4)\\n14. Grapefruit Juice, Concentrated, updated (running tally: 4/5)\\n15. Grapefruit Juice and Orange Juice, Concentrated, Blended, updated (running tally: 5/6)\\n16. Orange Juice, Concentrated, updated (running tally: 6/7)\\n17. Calculated the percentage (6 / 7 * 100% = 85.7%).\\n18. Rounded to the nearest percent (86%).', 'Number of steps': '14', 'How long did this take?': '20 minutes', 'Tools': '1. Web browser\\n2. Search engine\\n3. PDF access\\n4. Calculator', 'Number of tools': '4'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Path to your GAIA loader script\n",
    "loader_path = \"./GAIA.py\"\n",
    "\n",
    "# Levels to load\n",
    "levels = [\"2023_level1\", \"2023_level2\", \"2023_level3\"]\n",
    "\n",
    "# Dictionary to store one example from each\n",
    "examples = {}\n",
    "\n",
    "for level in levels:\n",
    "    dataset = load_dataset(loader_path, name=level, split=\"validation\")\n",
    "    examples[level] = dataset[0]  # Get the first item\n",
    "\n",
    "# Print the examples\n",
    "for level, example in examples.items():\n",
    "    print(f\"\\n--- Example from {level} ---\")\n",
    "    for k, v in example.items():\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f981a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2023_level1: 10 Examples ===\n",
      "\n",
      "--- Example 1 ---\n",
      "task_id: e1fc63a2-da7a-432f-be78-7c4a95598703\n",
      "Question: If Eliud Kipchoge could maintain his record-making marathon pace indefinitely, how many thousand hours would it take him to run the distance between the Earth and the Moon its closest approach? Please use the minimum perigee value on the Wikipedia page for the Moon when carrying out your calculation. Round your result to the nearest 1000 hours and do not use any comma separators if necessary.\n",
      "Level: 1\n",
      "Final answer: 17\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Googled Eliud Kipchoge marathon pace to find 4min 37sec/mile\\n2. Converted into fractions of hours.\\n3. Found moon periapsis in miles (225,623 miles).\\n4. Multiplied the two to find the number of hours and rounded to the nearest 100 hours.', 'Number of steps': '4', 'How long did this take?': '20 Minutes', 'Tools': '1. A web browser.\\n2. A search engine.\\n3. A calculator.', 'Number of tools': '3'}\n",
      "\n",
      "--- Example 2 ---\n",
      "task_id: 8e867cd7-cff9-4e6c-867a-ff5ddc2550be\n",
      "Question: How many studio albums were published by Mercedes Sosa between 2000 and 2009 (included)? You can use the latest 2022 version of english wikipedia.\n",
      "Level: 1\n",
      "Final answer: 3\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. I did a search for Mercedes Sosa\\n2. I went to the Wikipedia page for her\\n3. I scrolled down to \"Studio albums\"\\n4. I counted the ones between 2000 and 2009', 'Number of steps': '4', 'How long did this take?': '5 minutes', 'Tools': '1. web browser\\n2. google search', 'Number of tools': '2'}\n",
      "\n",
      "--- Example 3 ---\n",
      "task_id: ec09fa32-d03f-4bf8-84b0-1f16922c3ae4\n",
      "Question: Here's a fun riddle that I think you'll enjoy.\n",
      "\n",
      "You have been selected to play the final round of the hit new game show \"Pick That Ping-Pong\". In this round, you will be competing for a large cash prize. Your job will be to pick one of several different numbered ping-pong balls, and then the game will commence. The host describes how the game works.\n",
      "\n",
      "A device consisting of a winding clear ramp and a series of pistons controls the outcome of the game. The ramp feeds balls onto a platform. The platform has room for three ping-pong balls at a time. The three balls on the platform are each aligned with one of three pistons. At each stage of the game, one of the three pistons will randomly fire, ejecting the ball it strikes. If the piston ejects the ball in the first position on the platform the balls in the second and third position on the platform each advance one space, and the next ball on the ramp advances to the third position. If the piston ejects the ball in the second position, the ball in the first position is released and rolls away, the ball in the third position advances two spaces to occupy the first position, and the next two balls on the ramp advance to occupy the second and third positions on the platform. If the piston ejects the ball in the third position, the ball in the first position is released and rolls away, the ball in the second position advances one space to occupy the first position, and the next two balls on the ramp advance to occupy the second and third positions on the platform.\n",
      "\n",
      "The ramp begins with 100 numbered ping-pong balls, arranged in ascending order from 1 to 100. The host activates the machine and the first three balls, numbered 1, 2, and 3, advance to the platform. Before the random firing of the pistons begins, you are asked which of the 100 balls you would like to pick. If your pick is ejected by one of the pistons, you win the grand prize, $10,000.\n",
      "\n",
      "Which ball should you choose to maximize your odds of winning the big prize? Please provide your answer as the number of the ball selected.\n",
      "Level: 1\n",
      "Final answer: 3\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': 'Step 1: Evaluate the problem statement provided in my user\\'s prompt\\nStep 2: Consider the probability of any ball on the platform earning the prize.\\nStep 3: Evaluate the ball in position one. The probability of it earning the prize, P1, is 1/3\\nStep 4: Using a calculator, evaluate the ball in position two. The probability of it earning the prize, P2, is the difference between 1 and the product of the complementary probabilities for each trial\\nP2 = 1 - (2/3)(2/3)\\nP2 = 5/9\\nStep 5: Using a calculator, evaluate the ball in position three. The probability of it earning the prize, P3, is the difference between 1 and the product of the complementary probabilities for each trial\\nP3 = 1 - (2/3)(2/3)(2/3)\\nP3 = 19/27\\nStep 6: Consider the possible outcomes of numbers higher than 3.\\nStep 7: For each trial, either 1 or 2 balls from the ramp will advance to the platform. For any given selection, there is a 50% chance that the ball advances to position 2 or position 3.\\nStep 8: As position three holds the highest chance of earning the prize, select the only ball known to occupy position three with certainty, ball 3.\\nStep 9: Report the correct answer to my user, \"3\"', 'Number of steps': '9', 'How long did this take?': '1 minute', 'Tools': 'None', 'Number of tools': '0'}\n",
      "\n",
      "--- Example 4 ---\n",
      "task_id: 5d0080cb-90d7-4712-bc33-848150e917d3\n",
      "Question: What was the volume in m^3 of the fish bag that was calculated in the University of Leicester paper \"Can Hiccup Supply Enough Fish to Maintain a Dragonâ€™s Diet?\"\n",
      "Level: 1\n",
      "Final answer: 0.1777\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Searched \\'\"Can Hiccup Supply Enough Fish to Maintain a Dragonâ€™s Diet?\"\\' on Google.\\n2. Opened \"Can Hiccup Supply Enough Fish to Maintain a Dragonâ€™s Diet?\" at https://journals.le.ac.uk/ojs1/index.php/jist/article/view/733.\\n3. Clicked \"PDF\".\\n4. Found the calculations for the volume of the fish bag and noted them.', 'Number of steps': '4', 'How long did this take?': '5 minutes', 'Tools': '1. Web browser\\n2. Search engine\\n3. PDF access', 'Number of tools': '3'}\n",
      "\n",
      "--- Example 5 ---\n",
      "task_id: a1e91b78-d3d8-4675-bb8d-62741b4b68a6\n",
      "Question: In the video https://www.youtube.com/watch?v=L1vXCYZAYYM, what is the highest number of bird species to be on camera simultaneously?\n",
      "Level: 1\n",
      "Final answer: 3\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Navigate to the YouTube link.\\n2. Watch the video to see the highest number of bird species.\\n3. Note the number.', 'Number of steps': '3', 'How long did this take?': '3 minutes', 'Tools': '1. Web browser\\n2. Video parsing', 'Number of tools': '2'}\n",
      "\n",
      "--- Example 6 ---\n",
      "task_id: 46719c30-f4c3-4cad-be07-d5cb21eee6bb\n",
      "Question: Of the authors (First M. Last) that worked on the paper \"Pie Menus or Linear Menus, Which Is Better?\" in 2015, what was the title of the first paper authored by the one that had authored prior papers?\n",
      "Level: 1\n",
      "Final answer: Mapping Human Oriented Information to Software Agents for Online Systems Usage\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Searched \"Pie Menus or Linear Menus, Which Is Better?\" on Google.\\n2. Opened \"Pie Menus or Linear Menus, Which Is Better?\" on https://oda.oslomet.no/oda-xmlui/handle/10642/3162.\\n3. Clicked each author\\'s name.\\n4. Noted the name that had no other papers listed.\\n5. Searched \"Murano, Pietro\" on Google.\\n6. Opened http://www.pietromurano.org/.\\n7. Clicked \"Publications\".\\n8. Found the earliest paper he contributed to.', 'Number of steps': '8', 'How long did this take?': '10 minutes', 'Tools': '1. Web browser\\n2. Search engine', 'Number of tools': '2'}\n",
      "\n",
      "--- Example 7 ---\n",
      "task_id: 4b6bb5f7-f634-410e-815d-e673ab7f8632\n",
      "Question: In Series 9, Episode 11 of Doctor Who, the Doctor is trapped inside an ever-shifting maze. What is this location called in the official script for the episode? Give the setting exactly as it appears in the first scene heading.\n",
      "Level: 1\n",
      "Final answer: THE CASTLE\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Search the web for â€œDoctor Who series 9 episode 11 official scriptâ€.\\n2. Click result on the BBC website.\\n3. Scroll through the PDF to read the script, noting that it takes place in a mechanical castle location.\\n4. Scroll back to the first scene heading to note the answer, THE CASTLE', 'Number of steps': '4', 'How long did this take?': '5 minutes', 'Tools': '1. Search engine\\n2. Web browser\\n3. PDF viewer', 'Number of tools': '3'}\n",
      "\n",
      "--- Example 8 ---\n",
      "task_id: cffe0e32-c9a6-4c52-9877-78ceb4aaa9fb\n",
      "Question: An office held a Secret Santa gift exchange where each of its twelve employees was assigned one other employee in the group to present with a gift. Each employee filled out a profile including three likes or hobbies. On the day of the gift exchange, only eleven gifts were given, each one specific to one of the recipient's interests. Based on the information in the document, who did not give a gift?\n",
      "Level: 1\n",
      "Final answer: Fred\n",
      "file_name: cffe0e32-c9a6-4c52-9877-78ceb4aaa9fb.docx\n",
      "file_path: /mnt/data4/home/rrao/projects/GaiaBenchmarkHF/2023/validation/cffe0e32-c9a6-4c52-9877-78ceb4aaa9fb.docx\n",
      "Annotator Metadata: {'Steps': '1. Open the document.\\n2. Look at gifts and recipient interests.\\n3. Match Galileo Galilei biography (could apply to astronomy or books -> Miguel or Micah)\\n4. Match fishing reel (only applies to fishing -> Harry)\\n5. Match Raku programming guide (Perl language, but could also apply to JavaScript enthusiast - > Fred or Jun)\\n6. Match chisel set (could apply to camping or woodworking, but Harry is already fulfilled -> Jun, so Raku guide is for Fred)\\n7. Match custom dice (could apply to board games or tabletop RPGs -> Lucy or Sara)\\n8. Match â€œWar and Peaceâ€ American film copy (could apply to old movies or Audrey Hepburn -> Perry or Alex)\\n9. Match yarn (only applies to knitting -> Micah, so the Galileo biography is for Miguel)\\n10. Match \"One Piece\" graphic novel (could apply to books or manga, but Micah already has yarn -> Alex, so the \"War and Peace\" film is for Perry)\\n11. Match \"War and Peace\" novel (could apply to books or historical fiction novels, but Micah has yarn -> Tyson)\\n12. Match Starbucks gift card (only applies to coffee -> Lucy, so the dice are for Sara)\\n13. Match foam exercise mat (only applies to yoga -> Georgette)\\n14. Note which recipients have gifts (Miguel, Harry, Fred, Jun, Sara, Perry, Micah, Alex, Tyson, Lucy, Georgette) and which does not (Rebecca).\\n15. Find who was supposed to give Rebecca a gift (Fred).', 'Number of steps': '15', 'How long did this take?': '15 minutes', 'Tools': '1. Word document access', 'Number of tools': '1'}\n",
      "\n",
      "--- Example 9 ---\n",
      "task_id: 2d83110e-a098-4ebb-9987-066c06fa42d0\n",
      "Question: .rewsna eht sa \"tfel\" drow eht fo etisoppo eht etirw ,ecnetnes siht dnatsrednu uoy fI\n",
      "Level: 1\n",
      "Final answer: Right\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Read the instructions in reverse', 'Number of steps': '1', 'How long did this take?': '1 minute', 'Tools': '1. A word reversal tool / script', 'Number of tools': '0'}\n",
      "\n",
      "--- Example 10 ---\n",
      "task_id: 5cfb274c-0207-4aa7-9575-6ac0bd95d9b2\n",
      "Question: Each cell in the attached spreadsheet represents a plot of land. The color of the cell indicates who owns that plot. Green cells are plots owned by Earl Smith. Can Earl walk through every plot he owns (and no other plots) and return to his starting plot without backtracking? For this question, consider backtracking to be any instance where Earl would enter a plot of land he had already entered since leaving his starting plot.\n",
      "Level: 1\n",
      "Final answer: No\n",
      "file_name: 5cfb274c-0207-4aa7-9575-6ac0bd95d9b2.xlsx\n",
      "file_path: /mnt/data4/home/rrao/projects/GaiaBenchmarkHF/2023/validation/5cfb274c-0207-4aa7-9575-6ac0bd95d9b2.xlsx\n",
      "Annotator Metadata: {'Steps': '1. Open the spreadsheet\\n2. Analyze the green cells.\\n3. Note that the shape of Earlâ€™s plots is not a loop. There are dead-ends that canâ€™t be traversed without doubling back to a previously-traversed cell.', 'Number of steps': '3', 'How long did this take?': '1 minute', 'Tools': '1. Excel\\n2. Image recognition\\n3. Color recognition', 'Number of tools': '3'}\n"
     ]
    }
   ],
   "source": [
    "# We already have the loader_path and levels defined\n",
    "# Let's update to fetch 10 examples from each level\n",
    "num_examples = 10\n",
    "examples_list = {}\n",
    "\n",
    "for level in levels:\n",
    "    dataset = load_dataset(loader_path, name=level, split=\"validation\")\n",
    "    examples_list[level] = []\n",
    "    \n",
    "    # Get up to num_examples or as many as available\n",
    "    max_items = min(num_examples, len(dataset))\n",
    "    for i in range(max_items):\n",
    "        examples_list[level].append(dataset[i])\n",
    "\n",
    "# Print the examples\n",
    "for level, examples in examples_list.items():\n",
    "    print(f\"\\n=== {level}: {len(examples)} Examples ===\")\n",
    "    for i, example in enumerate(examples):\n",
    "        print(f\"\\n--- Example {i+1} ---\")\n",
    "        for k, v in example.items():\n",
    "            print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbbe0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 2023_level1 ###\n",
      "Error loading 2023_level1 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "\n",
      "Split: validation\n",
      "Total Questions: 53\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 42\n",
      "  - file_path: 42\n",
      "\n",
      "Split: test\n",
      "Total Questions: 93\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 68\n",
      "  - file_path: 68\n",
      "\n",
      "### 2023_level2 ###\n",
      "Error loading 2023_level2 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "\n",
      "Split: validation\n",
      "Total Questions: 86\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 66\n",
      "  - file_path: 66\n",
      "\n",
      "Split: test\n",
      "Total Questions: 159\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 127\n",
      "  - file_path: 127\n",
      "\n",
      "### 2023_level3 ###\n",
      "Error loading 2023_level3 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "\n",
      "Split: validation\n",
      "Total Questions: 26\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 19\n",
      "  - file_path: 19\n",
      "\n",
      "Split: test\n",
      "Total Questions: 49\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 35\n",
      "  - file_path: 35\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "loader_path = \"./GAIA.py\"\n",
    "levels = [\"2023_level1\", \"2023_level2\", \"2023_level3\"]\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "for level in levels:\n",
    "    print(f\"\\n### {level} ###\")\n",
    "    for split in splits:\n",
    "        try:\n",
    "            dataset = load_dataset(loader_path, name=level, split=split)\n",
    "            print(f\"\\nSplit: {split}\")\n",
    "            print(f\"Total Questions: {len(dataset)}\")\n",
    "\n",
    "            # Collect keys and check for missing values\n",
    "            all_keys = set()\n",
    "            missing_counts = {}\n",
    "\n",
    "            for item in dataset:\n",
    "                all_keys.update(item.keys())\n",
    "                for key in all_keys:\n",
    "                    if key not in item or item[key] in [None, \"\", [], {}]:\n",
    "                        missing_counts[key] = missing_counts.get(key, 0) + 1\n",
    "\n",
    "            print(\"Unique Keys:\", sorted(all_keys))\n",
    "            if missing_counts:\n",
    "                print(\"Missing values found in:\")\n",
    "                for key, count in missing_counts.items():\n",
    "                    print(f\"  - {key}: {count}\")\n",
    "            else:\n",
    "                print(\"No missing values.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {level} {split}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea728a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading 2023_level1 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "2023_level1 | validation -> 53\n",
      "2023_level1 | test -> 93\n",
      "Error loading 2023_level2 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "2023_level2 | validation -> 86\n",
      "2023_level2 | test -> 159\n",
      "Error loading 2023_level3 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "2023_level3 | validation -> 26\n",
      "2023_level3 | test -> 49\n",
      "\n",
      "ðŸ”¥ Total number of questions across all levels and splits: 466\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "loader_path = \"./GAIA.py\"\n",
    "levels = [\"2023_level1\", \"2023_level2\", \"2023_level3\"]\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "total = 0\n",
    "\n",
    "for level in levels:\n",
    "    for split in splits:\n",
    "        try:\n",
    "            dataset = load_dataset(loader_path, name=level, split=split)\n",
    "            count = len(dataset)\n",
    "            print(f\"{level} | {split} -> {count}\")\n",
    "            total += count\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {level} {split}: {e}\")\n",
    "\n",
    "print(f\"\\nðŸ”¥ Total number of questions across all levels and splits: {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951f636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833ef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nandan may refer to:\n",
      "No results found.\n",
      "No results found.\n",
      "Wikipedia is a free online encyclopedia, written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and the wiki software MediaWiki. Founded by Jimmy Wales and Larry Sanger on January 15, 2001, Wikipedia has been hosted since 2003 by the Wikimedia Foundation, an American nonprofit organization funded mainly by donations from readers. Wikipedia is the largest and most-read reference work in history.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def search_wikipedia(query):\n",
    "    # Step 1: Search for relevant pages\n",
    "    search_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": query,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = requests.get(search_url, params=params).json()\n",
    "    \n",
    "    search_results = response.get(\"query\", {}).get(\"search\", [])\n",
    "    if not search_results:\n",
    "        return \"No results found.\"\n",
    "    \n",
    "    # Step 2: Get the title of the first result\n",
    "    top_title = search_results[0][\"title\"]\n",
    "    \n",
    "    # Step 3: Fetch the summary of the top result\n",
    "    summary_url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{top_title.replace(' ', '_')}\"\n",
    "    summary_response = requests.get(summary_url).json()\n",
    "    return summary_response.get(\"extract\", \"No summary available.\")\n",
    "\n",
    "def agent(user_input):\n",
    "    return search_wikipedia(user_input)\n",
    "\n",
    "# Example usage\n",
    "while True:\n",
    "    user_input = input(\"Ask: \")\n",
    "    print(agent(user_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41029466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
