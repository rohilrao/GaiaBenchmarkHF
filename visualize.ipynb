{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892a5761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084ab48058ff4c66bfeef09dc4e097b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f468bb4fad674d9ba4a8ebf55bc3b520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8a518069d24a49945aba8ba9ef9d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efab32c5fd6549d496014b1d827db7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04016b9a61594e06b73115cb6ad08caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d55de906c1426e88adf86d89bb5189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example from 2023_level1 ---\n",
      "task_id: e1fc63a2-da7a-432f-be78-7c4a95598703\n",
      "Question: If Eliud Kipchoge could maintain his record-making marathon pace indefinitely, how many thousand hours would it take him to run the distance between the Earth and the Moon its closest approach? Please use the minimum perigee value on the Wikipedia page for the Moon when carrying out your calculation. Round your result to the nearest 1000 hours and do not use any comma separators if necessary.\n",
      "Level: 1\n",
      "Final answer: 17\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Googled Eliud Kipchoge marathon pace to find 4min 37sec/mile\\n2. Converted into fractions of hours.\\n3. Found moon periapsis in miles (225,623 miles).\\n4. Multiplied the two to find the number of hours and rounded to the nearest 100 hours.', 'Number of steps': '4', 'How long did this take?': '20 Minutes', 'Tools': '1. A web browser.\\n2. A search engine.\\n3. A calculator.', 'Number of tools': '3'}\n",
      "\n",
      "--- Example from 2023_level2 ---\n",
      "task_id: c61d22de-5f6c-4958-a7f6-5e9707bd3466\n",
      "Question: A paper about AI regulation that was originally submitted to arXiv.org in June 2022 shows a figure with three axes, where each axis has a label word at both ends. Which of these words is used to describe a type of society in a Physics and Society article submitted to arXiv.org on August 11, 2016?\n",
      "Level: 2\n",
      "Final answer: egalitarian\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Go to arxiv.org and navigate to the Advanced Search page.\\n2. Enter \"AI regulation\" in the search box and select \"All fields\" from the dropdown.\\n3. Enter 2022-06-01 and 2022-07-01 into the date inputs, select \"Submission date (original)\", and submit the search.\\n4. Go through the search results to find the article that has a figure with three axes and labels on each end of the axes, titled \"Fairness in Agreement With European Values: An Interdisciplinary Perspective on AI Regulation\".\\n5. Note the six words used as labels: deontological, egalitarian, localized, standardized, utilitarian, and consequential.\\n6. Go back to arxiv.org\\n7. Find \"Physics and Society\" and go to the page for the \"Physics and Society\" category.\\n8. Note that the tag for this category is \"physics.soc-ph\".\\n9. Go to the Advanced Search page.\\n10. Enter \"physics.soc-ph\" in the search box and select \"All fields\" from the dropdown.\\n11. Enter 2016-08-11 and 2016-08-12 into the date inputs, select \"Submission date (original)\", and submit the search.\\n12. Search for instances of the six words in the results to find the paper titled \"Phase transition from egalitarian to hierarchical societies driven by competition between cognitive and social constraints\", indicating that \"egalitarian\" is the correct answer.', 'Number of steps': '12', 'How long did this take?': '8 minutes', 'Tools': '1. Web browser\\n2. Image recognition tools (to identify and parse a figure with three axes)', 'Number of tools': '2'}\n",
      "\n",
      "--- Example from 2023_level3 ---\n",
      "task_id: 676e5e31-a554-4acc-9286-b60d90a92d26\n",
      "Question: In July 2, 1959 United States standards for grades of processed fruits, vegetables, and certain other products listed as dehydrated, consider the items in the \"dried and dehydrated section\" specifically marked as dehydrated along with any items in the Frozen/Chilled section that contain the whole name of the item, but not if they're marked Chilled. As of August 2023, what is the percentage (to the nearest percent) of those standards that have been superseded by a new version since the date given in the 1959 standards?\n",
      "Level: 3\n",
      "Final answer: 86\n",
      "file_name: \n",
      "file_path: \n",
      "Annotator Metadata: {'Steps': '1. Searched \"July 2, 1959 United States standards for grades of processed fruits, vegetables, and certain other products\" on Google.\\n2. Opened https://upload.wikimedia.org/wikipedia/commons/0/06/United_States_standards_for_grades_of_processed_fruits%2C_vegetables%2C_and_certain_other_products_%28as_of_July_2%2C_1959%29_%28IA_unitedstatesstan14unit_4%29.pdf.\\n3. Scrolled to the \"DRIED or DEHYDRATED\" section.\\n4. Opened a new tab and searched \"united states standards for grades of dehydrated apples\".\\n5. Opened https://www.ams.usda.gov/grades-standards/dehydrated-apples-grades-and-standards.\\n6. Opened the \"U.S. Grade Standards for Dehydrated Apples (pdf)\" PDF.\\n7. Checked the date against the 1959 standards.\\n8. Repeated steps 4-7 for all dehydrated items in the \"DRIED or DEHYDRATED\" section:\\n9. Grapefruit Juice, updated (running tally: 2/2)\\n10. Orange Juice, updated (running tally: 3/3)\\n11. Found all versions of the dehydrated items in Frozen or Chilled, except those marked Chilled: Apples; Grapefruit Juice, Concentrated; Grapefruit Juice and Orange Juice, Concentrated, Blended; Orange Juice, Concentrated\\n12. Repeated steps 4-7 all those versions:\\n13. Apples, not updated (running tally: 3/4)\\n14. Grapefruit Juice, Concentrated, updated (running tally: 4/5)\\n15. Grapefruit Juice and Orange Juice, Concentrated, Blended, updated (running tally: 5/6)\\n16. Orange Juice, Concentrated, updated (running tally: 6/7)\\n17. Calculated the percentage (6 / 7 * 100% = 85.7%).\\n18. Rounded to the nearest percent (86%).', 'Number of steps': '14', 'How long did this take?': '20 minutes', 'Tools': '1. Web browser\\n2. Search engine\\n3. PDF access\\n4. Calculator', 'Number of tools': '4'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Path to your GAIA loader script\n",
    "loader_path = \"./GAIA.py\"\n",
    "\n",
    "# Levels to load\n",
    "levels = [\"2023_level1\", \"2023_level2\", \"2023_level3\"]\n",
    "\n",
    "# Dictionary to store one example from each\n",
    "examples = {}\n",
    "\n",
    "for level in levels:\n",
    "    dataset = load_dataset(loader_path, name=level, split=\"validation\")\n",
    "    examples[level] = dataset[0]  # Get the first item\n",
    "\n",
    "# Print the examples\n",
    "for level, example in examples.items():\n",
    "    print(f\"\\n--- Example from {level} ---\")\n",
    "    for k, v in example.items():\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbbe0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 2023_level1 ###\n",
      "Error loading 2023_level1 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "\n",
      "Split: validation\n",
      "Total Questions: 53\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 42\n",
      "  - file_path: 42\n",
      "\n",
      "Split: test\n",
      "Total Questions: 93\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 68\n",
      "  - file_path: 68\n",
      "\n",
      "### 2023_level2 ###\n",
      "Error loading 2023_level2 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "\n",
      "Split: validation\n",
      "Total Questions: 86\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 66\n",
      "  - file_path: 66\n",
      "\n",
      "Split: test\n",
      "Total Questions: 159\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 127\n",
      "  - file_path: 127\n",
      "\n",
      "### 2023_level3 ###\n",
      "Error loading 2023_level3 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "\n",
      "Split: validation\n",
      "Total Questions: 26\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 19\n",
      "  - file_path: 19\n",
      "\n",
      "Split: test\n",
      "Total Questions: 49\n",
      "Unique Keys: ['Annotator Metadata', 'Final answer', 'Level', 'Question', 'file_name', 'file_path', 'task_id']\n",
      "Missing values found in:\n",
      "  - file_name: 35\n",
      "  - file_path: 35\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "loader_path = \"./GAIA.py\"\n",
    "levels = [\"2023_level1\", \"2023_level2\", \"2023_level3\"]\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "for level in levels:\n",
    "    print(f\"\\n### {level} ###\")\n",
    "    for split in splits:\n",
    "        try:\n",
    "            dataset = load_dataset(loader_path, name=level, split=split)\n",
    "            print(f\"\\nSplit: {split}\")\n",
    "            print(f\"Total Questions: {len(dataset)}\")\n",
    "\n",
    "            # Collect keys and check for missing values\n",
    "            all_keys = set()\n",
    "            missing_counts = {}\n",
    "\n",
    "            for item in dataset:\n",
    "                all_keys.update(item.keys())\n",
    "                for key in all_keys:\n",
    "                    if key not in item or item[key] in [None, \"\", [], {}]:\n",
    "                        missing_counts[key] = missing_counts.get(key, 0) + 1\n",
    "\n",
    "            print(\"Unique Keys:\", sorted(all_keys))\n",
    "            if missing_counts:\n",
    "                print(\"Missing values found in:\")\n",
    "                for key, count in missing_counts.items():\n",
    "                    print(f\"  - {key}: {count}\")\n",
    "            else:\n",
    "                print(\"No missing values.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {level} {split}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea728a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading 2023_level1 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "2023_level1 | validation -> 53\n",
      "2023_level1 | test -> 93\n",
      "Error loading 2023_level2 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "2023_level2 | validation -> 86\n",
      "2023_level2 | test -> 159\n",
      "Error loading 2023_level3 train: Unknown split \"train\". Should be one of ['test', 'validation'].\n",
      "2023_level3 | validation -> 26\n",
      "2023_level3 | test -> 49\n",
      "\n",
      "ðŸ”¥ Total number of questions across all levels and splits: 466\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "loader_path = \"./GAIA.py\"\n",
    "levels = [\"2023_level1\", \"2023_level2\", \"2023_level3\"]\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "total = 0\n",
    "\n",
    "for level in levels:\n",
    "    for split in splits:\n",
    "        try:\n",
    "            dataset = load_dataset(loader_path, name=level, split=split)\n",
    "            count = len(dataset)\n",
    "            print(f\"{level} | {split} -> {count}\")\n",
    "            total += count\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {level} {split}: {e}\")\n",
    "\n",
    "print(f\"\\nðŸ”¥ Total number of questions across all levels and splits: {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951f636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833ef06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
